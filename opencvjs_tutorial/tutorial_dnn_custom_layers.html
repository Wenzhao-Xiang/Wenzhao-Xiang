<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>OpenCV: Custom deep learning layers support</title>
<link href="opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="tutorial-utils.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          forkfour: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ #7 & \\mbox{#8}\\\\ \\end{array} \\right.", 8],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">4.1.1-dev</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="tutorial_root.html">OpenCV Tutorials</a></li><li class="navelem"><a class="el" href="tutorial_table_of_content_dnn.html">Deep Neural Networks (dnn module)</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Custom deep learning layers support </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Introduction</h2>
<p>Deep learning is a fast growing area. The new approaches to build neural networks usually introduce new types of layers. They could be modifications of existing ones or implement outstanding researching ideas.</p>
<p>OpenCV gives an opportunity to import and run networks from different deep learning frameworks. There are a number of the most popular layers. However you can face a problem that your network cannot be imported using OpenCV because of unimplemented layers.</p>
<p>The first solution is to create a feature request at <a href="https://github.com/opencv/opencv/issues">https://github.com/opencv/opencv/issues</a> mentioning details such a source of model and type of new layer. A new layer could be implemented if OpenCV community shares this need.</p>
<p>The second way is to define a <b>custom layer</b> so OpenCV's deep learning engine will know how to use it. This tutorial is dedicated to show you a process of deep learning models import customization.</p>
<h2>Define a custom layer in C++</h2>
<p>Deep learning layer is a building block of network's pipeline. It has connections to <b>input blobs</b> and produces results to <b>output blobs</b>. There are trained <b>weights</b> and <b>hyper-parameters</b>. Layers' names, types, weights and hyper-parameters are stored in files are generated by native frameworks during training. If OpenCV mets unknown layer type it throws an exception trying to read a model:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;Unspecified error: Can&#39;t create layer &quot;layer_name&quot; of type &quot;MyType&quot; in function getLayerInstance</div></div><!-- fragment --><p>To import the model correctly you have to derive a class from <a class="el" href="d3/d6c/classcv_1_1dnn_1_1Layer.html" title="This interface class allows to build new Layers - are building blocks of networks. ">cv::dnn::Layer</a> with the following methods:</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>MyLayer : <span class="keyword">public</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html">cv::dnn::Layer</a></div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    MyLayer(<span class="keyword">const</span> <a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a> &amp;params);</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a> create(<a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a>&amp; params);</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#aa5be9d5a6cef13d7c46c85bf8110dd4d">getMemoryShapes</a>(<span class="keyword">const</span> std::vector&lt;std::vector&lt;int&gt; &gt; &amp;inputs,</div><div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">int</span> requiredOutputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;outputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;internals) const <a class="code" href="db/de0/group__core__utils.html#ga4d89d63e402ef9ddc48e18e21180fe4a">CV_OVERRIDE</a>;</div><div class="line"></div><div class="line">    virtual <span class="keywordtype">void</span> forward(<a class="code" href="d2/d75/namespacecv.html">cv</a>::<a class="code" href="dc/d84/group__core__basic.html#ga606feabe3b50ab6838f1ba89727aa07a">InputArrayOfArrays</a> inputs,</div><div class="line">                         <a class="code" href="d2/d75/namespacecv.html">cv</a>::<a class="code" href="dc/d84/group__core__basic.html#ga889a09549b98223016170d9b613715de">OutputArrayOfArrays</a> outputs,</div><div class="line">                         <a class="code" href="d2/d75/namespacecv.html">cv</a>::<a class="code" href="dc/d84/group__core__basic.html#ga889a09549b98223016170d9b613715de">OutputArrayOfArrays</a> internals) CV_OVERRIDE;</div><div class="line"></div><div class="line">    virtual <span class="keywordtype">void</span> finalize(<a class="code" href="d2/d75/namespacecv.html">cv</a>::<a class="code" href="dc/d84/group__core__basic.html#ga606feabe3b50ab6838f1ba89727aa07a">InputArrayOfArrays</a> inputs,</div><div class="line">                          <a class="code" href="d2/d75/namespacecv.html">cv</a>::<a class="code" href="dc/d84/group__core__basic.html#ga889a09549b98223016170d9b613715de">OutputArrayOfArrays</a> outputs) CV_OVERRIDE;</div><div class="line">};</div></div><!-- fragment --><p> And register it before the import:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;<a class="code" href="df/d8c/layer_8details_8hpp.html">opencv2/dnn/layer.details.hpp</a>&gt;</span>  <span class="comment">// CV_DNN_REGISTER_LAYER_CLASS</span></div><div class="line"></div><div class="line"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keywordtype">void</span> loadNet()</div><div class="line">{</div><div class="line">    <a class="code" href="df/d8c/layer_8details_8hpp.html#a7e8d9c0c5849b6a081ba2a84845f3dac">CV_DNN_REGISTER_LAYER_CLASS</a>(Interp, InterpLayer);</div><div class="line">    <span class="comment">// ...</span></div></div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><code>MyType</code> is a type of unimplemented layer from the thrown exception.</dd></dl>
<p>Let's see what all the methods do:</p>
<ul>
<li>Constructor</li>
</ul>
<div class="fragment"><div class="line">    MyLayer(<span class="keyword">const</span> <a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a> &amp;params);</div></div><!-- fragment --><p> Retrieves hyper-parameters from <a class="el" href="db/db6/classcv_1_1dnn_1_1LayerParams.html" title="This class provides all data needed to initialize layer. ">cv::dnn::LayerParams</a>. If your layer has trainable weights they will be already stored in the Layer's member <a class="el" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a9a5578e0b3a0ec0301fb7320b54aa6ed" title="List of learned parameters must be stored here to allow read them by using Net::getParam(). ">cv::dnn::Layer::blobs</a>.</p>
<ul>
<li>A static method <code>create</code></li>
</ul>
<div class="fragment"><div class="line">    <span class="keyword">static</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a> create(<a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a>&amp; params);</div></div><!-- fragment --><p> This method should create an instance of you layer and return <a class="el" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr</a> with it.</p>
<ul>
<li>Output blobs' shape computation</li>
</ul>
<div class="fragment"><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> getMemoryShapes(<span class="keyword">const</span> std::vector&lt;std::vector&lt;int&gt; &gt; &amp;inputs,</div><div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">int</span> requiredOutputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;outputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;internals) const CV_OVERRIDE;</div></div><!-- fragment --><p> Returns layer's output shapes depends on input shapes. You may request an extra memory using <code>internals</code>.</p>
<ul>
<li>Run a layer</li>
</ul>
<div class="fragment"><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> forward(<a class="code" href="d4/d32/classcv_1_1__InputArray.html">cv::InputArrayOfArrays</a> inputs,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> outputs,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> internals) <a class="code" href="db/de0/group__core__utils.html#ga4d89d63e402ef9ddc48e18e21180fe4a">CV_OVERRIDE</a>;</div></div><!-- fragment --><p> Implement a layer's logic here. Compute outputs for given inputs.</p>
<dl class="section note"><dt>Note</dt><dd>OpenCV manages memory allocated for layers. In the most cases the same memory can be reused between layers. So your <code>forward</code> implementation should not rely that the second invocation of <code>forward</code> will has the same data at <code>outputs</code> and <code>internals</code>.</dd></dl>
<ul>
<li>Optional <code>finalize</code> method</li>
</ul>
<div class="fragment"><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> finalize(<a class="code" href="d4/d32/classcv_1_1__InputArray.html">cv::InputArrayOfArrays</a> inputs,</div><div class="line">                          <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> outputs) <a class="code" href="db/de0/group__core__utils.html#ga4d89d63e402ef9ddc48e18e21180fe4a">CV_OVERRIDE</a>;</div></div><!-- fragment --><p> The chain of methods are the following: OpenCV deep learning engine calls <code>create</code> method once then it calls <code>getMemoryShapes</code> for an every created layer then you can make some preparations depends on known input dimensions at <a class="el" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a16e8d282842ce091953dbcf181d2facb" title="Computes and sets internal parameters according to inputs, outputs and blobs. ">cv::dnn::Layer::finalize</a>. After network was initialized only <code>forward</code> method is called for an every network's input.</p>
<dl class="section note"><dt>Note</dt><dd>Varying input blobs' sizes such height or width or batch size you make OpenCV reallocate all the internal memory. That leads efficiency gaps. Try to initialize and deploy models using a fixed batch size and image's dimensions.</dd></dl>
<h2>Example: custom layer from Caffe</h2>
<p>Let's create a custom layer <code>Interp</code> from <a href="https://github.com/cdmh/deeplab-public">https://github.com/cdmh/deeplab-public</a>. It's just a simple resize that takes an input blob of size <code>N x C x Hi x Wi</code> and returns an output blob of size <code>N x C x Ho x Wo</code> where <code>N</code> is a batch size, <code>C</code> is a number of channels, <code>Hi x Wi</code> and <code>Ho x Wo</code> are input and output <code>height x width</code> correspondingly. This layer has no trainable weights but it has hyper-parameters to specify an output size.</p>
<p>In example, </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;layer {</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;  name: &quot;output&quot;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;  type: &quot;Interp&quot;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;  bottom: &quot;input&quot;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;  top: &quot;output&quot;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;  interp_param {</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;    height: 9</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;    width: 8</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;  }</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;}</div></div><!-- fragment --><p>This way our implementation can look like:</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>InterpLayer : <span class="keyword">public</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html">cv::dnn::Layer</a></div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    InterpLayer(<span class="keyword">const</span> <a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a> &amp;params) : Layer(params)</div><div class="line">    {</div><div class="line">        outWidth = params.<a class="code" href="d9/d2b/classcv_1_1dnn_1_1Dict.html#a35c56a19b2abeba2a25f7c8a01efe382">get</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;width&quot;</span>, 0);</div><div class="line">        outHeight = params.<a class="code" href="d9/d2b/classcv_1_1dnn_1_1Dict.html#a35c56a19b2abeba2a25f7c8a01efe382">get</a>&lt;<span class="keywordtype">int</span>&gt;(<span class="stringliteral">&quot;height&quot;</span>, 0);</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a> create(<a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a>&amp; params)</div><div class="line">    {</div><div class="line">        <span class="keywordflow">return</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a>(<span class="keyword">new</span> InterpLayer(params));</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#aa5be9d5a6cef13d7c46c85bf8110dd4d">getMemoryShapes</a>(<span class="keyword">const</span> std::vector&lt;std::vector&lt;int&gt; &gt; &amp;inputs,</div><div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">int</span> requiredOutputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;outputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;internals) const CV_OVERRIDE</div><div class="line">    {</div><div class="line">        CV_UNUSED(requiredOutputs); CV_UNUSED(internals);</div><div class="line">        std::vector&lt;int&gt; outShape(4);</div><div class="line">        outShape[0] = inputs[0][0];  <span class="comment">// batch size</span></div><div class="line">        outShape[1] = inputs[0][1];  <span class="comment">// number of channels</span></div><div class="line">        outShape[2] = outHeight;</div><div class="line">        outShape[3] = outWidth;</div><div class="line">        outputs.assign(1, outShape);</div><div class="line">        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// Implementation of this custom layer is based on https://github.com/cdmh/deeplab-public/blob/master/src/caffe/layers/interp_layer.cpp</span></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a7d9cf7133a388311bce8ef9344f1b923">forward</a>(<a class="code" href="d4/d32/classcv_1_1__InputArray.html">cv::InputArrayOfArrays</a> inputs_arr,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> outputs_arr,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> internals_arr) CV_OVERRIDE</div><div class="line">    {</div><div class="line">        <span class="keywordflow">if</span> (inputs_arr.depth() == <a class="code" href="d1/d1b/group__core__hal__interface.html#ga9d2ee1a8334733dea7482a47a88e0f87">CV_16S</a>)</div><div class="line">        {</div><div class="line">            <span class="comment">// In case of DNN_TARGET_OPENCL_FP16 target the following method</span></div><div class="line">            <span class="comment">// converts data from FP16 to FP32 and calls this forward again.</span></div><div class="line">            <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#ae240acf2b7ad43531ca903c927334c8a">forward_fallback</a>(inputs_arr, outputs_arr, internals_arr);</div><div class="line">            <span class="keywordflow">return</span>;</div><div class="line">        }</div><div class="line"></div><div class="line">        std::vector&lt;cv::Mat&gt; inputs, outputs;</div><div class="line">        inputs_arr.getMatVector(inputs);</div><div class="line">        outputs_arr.getMatVector(outputs);</div><div class="line"></div><div class="line">        <a class="code" href="d3/d63/classcv_1_1Mat.html">cv::Mat</a>&amp; inp = inputs[0];</div><div class="line">        <a class="code" href="d3/d63/classcv_1_1Mat.html">cv::Mat</a>&amp; out = outputs[0];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span>* inpData = (<span class="keywordtype">float</span>*)inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a4d33bed1c850265370d2af0ff02e1564">data</a>;</div><div class="line">        <span class="keywordtype">float</span>* outData = (<span class="keywordtype">float</span>*)out.<a class="code" href="d3/d63/classcv_1_1Mat.html#a4d33bed1c850265370d2af0ff02e1564">data</a>;</div><div class="line"></div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> batchSize = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[0];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> numChannels = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[1];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> inpHeight = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[2];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> inpWidth = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[3];</div><div class="line"></div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span> rheight = (outHeight &gt; 1) ? static_cast&lt;float&gt;(inpHeight - 1) / (outHeight - 1) : 0.f;</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span> rwidth = (outWidth &gt; 1) ? static_cast&lt;float&gt;(inpWidth - 1) / (outWidth - 1) : 0.f;</div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> h2 = 0; h2 &lt; outHeight; ++h2)</div><div class="line">        {</div><div class="line">            <span class="keyword">const</span> <span class="keywordtype">float</span> h1r = rheight * h2;</div><div class="line">            <span class="keyword">const</span> <span class="keywordtype">int</span> h1 = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(h1r);</div><div class="line">            <span class="keyword">const</span> <span class="keywordtype">int</span> h1p = (h1 &lt; inpHeight - 1) ? 1 : 0;</div><div class="line">            <span class="keyword">const</span> <span class="keywordtype">float</span> h1lambda = h1r - h1;</div><div class="line">            <span class="keyword">const</span> <span class="keywordtype">float</span> h0lambda = 1.f - h1lambda;</div><div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> w2 = 0; w2 &lt; outWidth; ++w2)</div><div class="line">            {</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">float</span> w1r = rwidth * w2;</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">int</span> w1 = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(w1r);</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">int</span> w1p = (w1 &lt; inpWidth - 1) ? 1 : 0;</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">float</span> w1lambda = w1r - w1;</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">float</span> w0lambda = 1.f - w1lambda;</div><div class="line">                <span class="keyword">const</span> <span class="keywordtype">float</span>* pos1 = inpData + h1 * inpWidth + w1;</div><div class="line">                <span class="keywordtype">float</span>* pos2 = outData + h2 * outWidth + w2;</div><div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; batchSize * numChannels; ++c)</div><div class="line">                {</div><div class="line">                    pos2[0] =</div><div class="line">                      h0lambda * (w0lambda * pos1[0] + w1lambda * pos1[w1p]) +</div><div class="line">                      h1lambda * (w0lambda * pos1[h1p * inpWidth] + w1lambda * pos1[h1p * inpWidth + w1p]);</div><div class="line">                    pos1 += inpWidth * inpHeight;</div><div class="line">                    pos2 += outWidth * outHeight;</div><div class="line">                }</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keywordtype">int</span> outWidth, outHeight;</div><div class="line">};</div></div><!-- fragment --><p> Next we need to register a new layer type and try to import the model.</p>
<div class="fragment"><div class="line">    <a class="code" href="df/d8c/layer_8details_8hpp.html#a7e8d9c0c5849b6a081ba2a84845f3dac">CV_DNN_REGISTER_LAYER_CLASS</a>(Interp, InterpLayer);</div><div class="line">    <a class="code" href="db/d30/classcv_1_1dnn_1_1Net.html">cv::dnn::Net</a> caffeNet = <a class="code" href="d6/d0f/group__dnn.html#ga3b34fe7a29494a6a4295c169a7d32422">cv::dnn::readNet</a>(<span class="stringliteral">&quot;/path/to/config.prototxt&quot;</span>, <span class="stringliteral">&quot;/path/to/weights.caffemodel&quot;</span>);</div></div><!-- fragment --> <h2>Example: custom layer from TensorFlow</h2>
<p>This is an example of how to import a network with <a href="https://www.tensorflow.org/versions/master/api_docs/python/tf/image/resize_bilinear">tf.image.resize_bilinear</a> operation. This is also a resize but with an implementation different from OpenCV's or <code>Interp</code> above.</p>
<p>Let's create a single layer network: </p><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;inp = tf.placeholder(tf.float32, [2, 3, 4, 5], <span class="stringliteral">&#39;input&#39;</span>)</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;resized = tf.image.resize_bilinear(inp, size=[9, 8], name=<span class="stringliteral">&#39;resize_bilinear&#39;</span>)</div></div><!-- fragment --><p> OpenCV sees that TensorFlow's graph in the following way:</p>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;node {</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;  name: &quot;input&quot;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;  op: &quot;Placeholder&quot;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;  attr {</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;    key: &quot;dtype&quot;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;    value {</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;      type: DT_FLOAT</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;    }</div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;  }</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;}</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;node {</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;  name: &quot;resize_bilinear/size&quot;</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;  op: &quot;Const&quot;</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;  attr {</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;    key: &quot;dtype&quot;</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;    value {</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;      type: DT_INT32</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;    }</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;  }</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;  attr {</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;    key: &quot;value&quot;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;    value {</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;      tensor {</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;        dtype: DT_INT32</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;        tensor_shape {</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;          dim {</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;            size: 2</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;          }</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;        }</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;        tensor_content: &quot;\t\000\000\000\010\000\000\000&quot;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;      }</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    }</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;  }</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;}</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;node {</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;  name: &quot;resize_bilinear&quot;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;  op: &quot;ResizeBilinear&quot;</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  input: &quot;input:0&quot;</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  input: &quot;resize_bilinear/size&quot;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  attr {</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    key: &quot;T&quot;</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    value {</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;      type: DT_FLOAT</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    }</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;  }</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  attr {</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;    key: &quot;align_corners&quot;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    value {</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;      b: false</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    }</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;  }</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;}</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;library {</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;}</div></div><!-- fragment --><p> Custom layers import from TensorFlow is designed to put all layer's <code>attr</code> into <a class="el" href="db/db6/classcv_1_1dnn_1_1LayerParams.html" title="This class provides all data needed to initialize layer. ">cv::dnn::LayerParams</a> but input <code>Const</code> blobs into <a class="el" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a9a5578e0b3a0ec0301fb7320b54aa6ed" title="List of learned parameters must be stored here to allow read them by using Net::getParam(). ">cv::dnn::Layer::blobs</a>. In our case resize's output shape will be stored in layer's <code>blobs[0]</code>.</p>
<div class="fragment"><div class="line"><span class="keyword">class </span>ResizeBilinearLayer <a class="code" href="db/de0/group__core__utils.html#ga8b49a79bdb8458a658db563481a19f4e">CV_FINAL</a> : <span class="keyword">public</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html">cv::dnn::Layer</a></div><div class="line">{</div><div class="line"><span class="keyword">public</span>:</div><div class="line">    ResizeBilinearLayer(<span class="keyword">const</span> <a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a> &amp;params) : Layer(params)</div><div class="line">    {</div><div class="line">        <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(!params.<a class="code" href="d9/d2b/classcv_1_1dnn_1_1Dict.html#a35c56a19b2abeba2a25f7c8a01efe382">get</a>&lt;<span class="keywordtype">bool</span>&gt;(<span class="stringliteral">&quot;align_corners&quot;</span>, <span class="keyword">false</span>));</div><div class="line">        <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(!blobs.empty());</div><div class="line"></div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; blobs.size(); ++i)</div><div class="line">            <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(blobs[i].<a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a5f3cdb2524e281094e14e212a76a2d38">type</a>() == <a class="code" href="d1/d1b/group__core__hal__interface.html#ga32f03fbb8f73bff70215b77f5c3cac11">CV_32SC1</a>);</div><div class="line"></div><div class="line">        <span class="comment">// There are two cases of input blob: a single blob which contains output</span></div><div class="line">        <span class="comment">// shape and two blobs with scaling factors.</span></div><div class="line">        <span class="keywordflow">if</span> (blobs.size() == 1)</div><div class="line">        {</div><div class="line">            <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(blobs[0].<a class="code" href="df/d57/namespacecv_1_1dnn.html#a65ad6cf1b64a572bf78d696d2014b0e6">total</a>() == 2);</div><div class="line">            outHeight = blobs[0].at&lt;<span class="keywordtype">int</span>&gt;(0, 0);</div><div class="line">            outWidth = blobs[0].at&lt;<span class="keywordtype">int</span>&gt;(0, 1);</div><div class="line">            factorHeight = factorWidth = 0;</div><div class="line">        }</div><div class="line">        <span class="keywordflow">else</span></div><div class="line">        {</div><div class="line">            <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(blobs.size() == 2); <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(blobs[0].<a class="code" href="df/d57/namespacecv_1_1dnn.html#a65ad6cf1b64a572bf78d696d2014b0e6">total</a>() == 1); <a class="code" href="db/de0/group__core__utils.html#gaf62bcd90f70e275191ab95136d85906b">CV_Assert</a>(blobs[1].<a class="code" href="df/d57/namespacecv_1_1dnn.html#a65ad6cf1b64a572bf78d696d2014b0e6">total</a>() == 1);</div><div class="line">            factorHeight = blobs[0].at&lt;<span class="keywordtype">int</span>&gt;(0, 0);</div><div class="line">            factorWidth = blobs[1].at&lt;<span class="keywordtype">int</span>&gt;(0, 0);</div><div class="line">            outHeight = outWidth = 0;</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">static</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a> create(<a class="code" href="db/db6/classcv_1_1dnn_1_1LayerParams.html">cv::dnn::LayerParams</a>&amp; params)</div><div class="line">    {</div><div class="line">        <span class="keywordflow">return</span> <a class="code" href="dc/d84/group__core__basic.html#ga6395ca871a678020c4a31fadf7e8cc63">cv::Ptr&lt;cv::dnn::Layer&gt;</a>(<span class="keyword">new</span> ResizeBilinearLayer(params));</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">bool</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#aa5be9d5a6cef13d7c46c85bf8110dd4d">getMemoryShapes</a>(<span class="keyword">const</span> std::vector&lt;std::vector&lt;int&gt; &gt; &amp;inputs,</div><div class="line">                                 <span class="keyword">const</span> <span class="keywordtype">int</span>,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;outputs,</div><div class="line">                                 std::vector&lt;std::vector&lt;int&gt; &gt; &amp;) const CV_OVERRIDE</div><div class="line">    {</div><div class="line">        std::vector&lt;int&gt; outShape(4);</div><div class="line">        outShape[0] = inputs[0][0];  <span class="comment">// batch size</span></div><div class="line">        outShape[1] = inputs[0][1];  <span class="comment">// number of channels</span></div><div class="line">        outShape[2] = outHeight != 0 ? outHeight : (inputs[0][2] * factorHeight);</div><div class="line">        outShape[3] = outWidth != 0 ? outWidth : (inputs[0][3] * factorWidth);</div><div class="line">        outputs.assign(1, outShape);</div><div class="line">        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a16e8d282842ce091953dbcf181d2facb">finalize</a>(<a class="code" href="d4/d32/classcv_1_1__InputArray.html">cv::InputArrayOfArrays</a>, <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> outputs_arr) CV_OVERRIDE</div><div class="line">    {</div><div class="line">        std::vector&lt;cv::Mat&gt; outputs;</div><div class="line">        outputs_arr.getMatVector(outputs);</div><div class="line">        <span class="keywordflow">if</span> (!outWidth &amp;&amp; !outHeight)</div><div class="line">        {</div><div class="line">            outHeight = outputs[0].size[2];</div><div class="line">            outWidth = outputs[0].size[3];</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="comment">// This implementation is based on a reference implementation from</span></div><div class="line">    <span class="comment">// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/internal/reference/reference_ops.h</span></div><div class="line">    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#a7d9cf7133a388311bce8ef9344f1b923">forward</a>(<a class="code" href="d4/d32/classcv_1_1__InputArray.html">cv::InputArrayOfArrays</a> inputs_arr,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> outputs_arr,</div><div class="line">                         <a class="code" href="d2/d9e/classcv_1_1__OutputArray.html">cv::OutputArrayOfArrays</a> internals_arr) CV_OVERRIDE</div><div class="line">    {</div><div class="line">        <span class="keywordflow">if</span> (inputs_arr.depth() == <a class="code" href="d1/d1b/group__core__hal__interface.html#ga9d2ee1a8334733dea7482a47a88e0f87">CV_16S</a>)</div><div class="line">        {</div><div class="line">            <span class="comment">// In case of DNN_TARGET_OPENCL_FP16 target the following method</span></div><div class="line">            <span class="comment">// converts data from FP16 to FP32 and calls this forward again.</span></div><div class="line">            <a class="code" href="d3/d6c/classcv_1_1dnn_1_1Layer.html#ae240acf2b7ad43531ca903c927334c8a">forward_fallback</a>(inputs_arr, outputs_arr, internals_arr);</div><div class="line">            <span class="keywordflow">return</span>;</div><div class="line">        }</div><div class="line"></div><div class="line">        std::vector&lt;cv::Mat&gt; inputs, outputs;</div><div class="line">        inputs_arr.getMatVector(inputs);</div><div class="line">        outputs_arr.getMatVector(outputs);</div><div class="line"></div><div class="line">        <a class="code" href="d3/d63/classcv_1_1Mat.html">cv::Mat</a>&amp; inp = inputs[0];</div><div class="line">        <a class="code" href="d3/d63/classcv_1_1Mat.html">cv::Mat</a>&amp; out = outputs[0];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">float</span>* inpData = (<span class="keywordtype">float</span>*)inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a4d33bed1c850265370d2af0ff02e1564">data</a>;</div><div class="line">        <span class="keywordtype">float</span>* outData = (<span class="keywordtype">float</span>*)out.<a class="code" href="d3/d63/classcv_1_1Mat.html#a4d33bed1c850265370d2af0ff02e1564">data</a>;</div><div class="line"></div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> batchSize = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[0];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> numChannels = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[1];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> inpHeight = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[2];</div><div class="line">        <span class="keyword">const</span> <span class="keywordtype">int</span> inpWidth = inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>[3];</div><div class="line"></div><div class="line">        <span class="keywordtype">float</span> heightScale = <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(inpHeight) / outHeight;</div><div class="line">        <span class="keywordtype">float</span> widthScale = <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(inpWidth) / outWidth;</div><div class="line">        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> b = 0; b &lt; batchSize; ++b)</div><div class="line">        {</div><div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> y = 0; y &lt; outHeight; ++y)</div><div class="line">            {</div><div class="line">                <span class="keywordtype">float</span> input_y = y * heightScale;</div><div class="line">                <span class="keywordtype">int</span> y0 = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(std::floor(input_y));</div><div class="line">                <span class="keywordtype">int</span> y1 = <a class="code" href="d7/dcc/group__core__utils__softfloat.html#gac48df53b8fd34b87e7b121fa8fd4c379">std::min</a>(y0 + 1, inpHeight - 1);</div><div class="line">                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> x = 0; x &lt; outWidth; ++x)</div><div class="line">                {</div><div class="line">                    <span class="keywordtype">float</span> input_x = x * widthScale;</div><div class="line">                    <span class="keywordtype">int</span> x0 = <span class="keyword">static_cast&lt;</span><span class="keywordtype">int</span><span class="keyword">&gt;</span>(std::floor(input_x));</div><div class="line">                    <span class="keywordtype">int</span> x1 = <a class="code" href="d7/dcc/group__core__utils__softfloat.html#gac48df53b8fd34b87e7b121fa8fd4c379">std::min</a>(x0 + 1, inpWidth - 1);</div><div class="line">                    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> c = 0; c &lt; numChannels; ++c)</div><div class="line">                    {</div><div class="line">                        <span class="keywordtype">float</span> interpolation =</div><div class="line">                            inpData[offset(inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>, c, x0, y0, b)] * (1 - (input_y - y0)) * (1 - (input_x - x0)) +</div><div class="line">                            inpData[offset(inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>, c, x0, y1, b)] * (input_y - y0) * (1 - (input_x - x0)) +</div><div class="line">                            inpData[offset(inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>, c, x1, y0, b)] * (1 - (input_y - y0)) * (input_x - x0) +</div><div class="line">                            inpData[offset(inp.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>, c, x1, y1, b)] * (input_y - y0) * (input_x - x0);</div><div class="line">                        outData[offset(out.<a class="code" href="d3/d63/classcv_1_1Mat.html#a146f8e8dda07d1365a575ab83d9828d1">size</a>, c, x, y, b)] = interpolation;</div><div class="line">                    }</div><div class="line">                }</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line"><span class="keyword">private</span>:</div><div class="line">    <span class="keyword">static</span> <span class="keyword">inline</span> <span class="keywordtype">int</span> offset(<span class="keyword">const</span> <a class="code" href="df/d63/structcv_1_1MatSize.html">cv::MatSize</a>&amp; size, <span class="keywordtype">int</span> c, <span class="keywordtype">int</span> x, <span class="keywordtype">int</span> y, <span class="keywordtype">int</span> b)</div><div class="line">    {</div><div class="line">        <span class="keywordflow">return</span> x + size[3] * (y + size[2] * (c + size[1] * b));</div><div class="line">    }</div><div class="line"></div><div class="line">    <span class="keywordtype">int</span> outWidth, outHeight, factorWidth, factorHeight;</div><div class="line">};</div></div><!-- fragment --><p> Next we register a layer and try to import the model.</p>
<div class="fragment"><div class="line">    <a class="code" href="df/d8c/layer_8details_8hpp.html#a7e8d9c0c5849b6a081ba2a84845f3dac">CV_DNN_REGISTER_LAYER_CLASS</a>(ResizeBilinear, ResizeBilinearLayer);</div><div class="line">    <a class="code" href="db/d30/classcv_1_1dnn_1_1Net.html">cv::dnn::Net</a> tfNet = <a class="code" href="d6/d0f/group__dnn.html#ga3b34fe7a29494a6a4295c169a7d32422">cv::dnn::readNet</a>(<span class="stringliteral">&quot;/path/to/graph.pb&quot;</span>);</div></div><!-- fragment --> <h2>Define a custom layer in Python</h2>
<p>The following example shows how to customize OpenCV's layers in Python.</p>
<p>Let's consider <a href="https://arxiv.org/abs/1504.06375">Holistically-Nested Edge Detection</a> deep learning model. That was trained with one and only difference comparing to a current version of <a href="http://caffe.berkeleyvision.org/">Caffe framework</a>. <code>Crop</code> layers that receive two input blobs and crop the first one to match spatial dimensions of the second one used to crop from the center. Nowadays Caffe's layer does it from the top-left corner. So using the latest version of Caffe or OpenCV you'll get shifted results with filled borders.</p>
<p>Next we're going to replace OpenCV's <code>Crop</code> layer that makes top-left cropping by a centric one.</p>
<ul>
<li>Create a class with <code>getMemoryShapes</code> and <code>forward</code> methods</li>
</ul>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="keyword">class </span>CropLayer(object):</div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;    <span class="keyword">def </span>__init__(self, params, blobs):</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;        self.xstart = 0</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;        self.xend = 0</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;        self.ystart = 0</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;        self.yend = 0</div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;</div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;    <span class="comment"># Our layer receives two inputs. We need to crop the first input blob</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;    <span class="comment"># to match a shape of the second one (keeping batch size and number of channels)</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;    <span class="keyword">def </span>getMemoryShapes(self, inputs):</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;        inputShape, targetShape = inputs[0], inputs[1]</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;        batchSize, numChannels = inputShape[0], inputShape[1]</div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;        height, width = targetShape[2], targetShape[3]</div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;</div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;        self.ystart = (inputShape[2] - targetShape[2]) // 2</div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;        self.xstart = (inputShape[3] - targetShape[3]) // 2</div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;        self.yend = self.ystart + height</div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;        self.xend = self.xstart + width</div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;        <span class="keywordflow">return</span> [[batchSize, numChannels, height, width]]</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;    <span class="keyword">def </span>forward(self, inputs):</div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;        <span class="keywordflow">return</span> [inputs[0][:,:,self.ystart:self.yend,self.xstart:self.xend]]</div></div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd>Both methods should return lists.</dd></dl>
<ul>
<li>Register a new layer.</li>
</ul>
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;cv.dnn_registerLayer(<span class="stringliteral">&#39;Crop&#39;</span>, CropLayer)</div></div><!-- fragment --><p> That's it! We've replaced an implemented OpenCV's layer to a custom one. You may find a full script in the <a href="https://github.com/opencv/opencv/tree/master/samples/dnn/edge_detection.py">source code</a>.</p>
<table  border="0">
<tr>
<td><div class="image">
<img src="lena.jpg" alt="lena.jpg"/>
</div>
 </td><td><div class="image">
<img src="lena_hed.jpg" alt="lena_hed.jpg"/>
</div>
  </td></tr>
</table>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Aug 22 2019 16:32:37 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<script type="text/javascript">
//<![CDATA[
addTutorialsButtons();
//]]>
</script>
</body>
</html>
